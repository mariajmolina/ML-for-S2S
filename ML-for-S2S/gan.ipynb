{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, os, torch, numpy as np\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "#seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "import torch.fft\n",
    "import subprocess\n",
    "import logging\n",
    "#import random\n",
    "import shutil\n",
    "import psutil\n",
    "import sklearn\n",
    "import scipy\n",
    "#import torch\n",
    "import copy\n",
    "import yaml\n",
    "import time\n",
    "import tqdm\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import torch\n",
    "\n",
    "#from holodecml.data import PickleReader, UpsamplingReader, XarrayReader, XarrayReaderLabels\n",
    "#from holodecml.propagation import InferencePropagator\n",
    "from holodecml.transforms import LoadTransformations\n",
    "from holodecml.models import load_model\n",
    "from holodecml.losses import load_loss\n",
    "\n",
    "#import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn, sklearn.metrics\n",
    "\n",
    "def man_metrics(results):\n",
    "    result = {}\n",
    "    for metric in [\"f1\", \"auc\", 'pod', \"far\", \"csi\"]: #\"man_prec\", \"man_recall\",\n",
    "        if metric == 'f1':\n",
    "            score = sklearn.metrics.f1_score(results[\"true\"], results[\"pred\"], average = \"weighted\")\n",
    "        elif metric == 'prec':\n",
    "            score = sklearn.metrics.precision_score(results[\"true\"], results[\"pred\"], average = \"weighted\")\n",
    "        elif metric == 'recall':\n",
    "            score = sklearn.metrics.recall_score(results[\"true\"], results[\"pred\"], average = \"weighted\")\n",
    "        elif metric == 'auc':\n",
    "            try:\n",
    "                score = sklearn.metrics.roc_auc_score(results[\"true\"], results[\"pred\"], average = \"weighted\")\n",
    "            except:\n",
    "                score = 1.0\n",
    "        elif metric ==  \"csi\":\n",
    "            try:\n",
    "                TN, FP, FN, TP = sklearn.metrics.confusion_matrix(results[\"true\"], results[\"pred\"]).ravel()\n",
    "                score = TP / (TP + FN + FP)\n",
    "            except:\n",
    "                score = 1\n",
    "        elif metric == 'far':\n",
    "            try:\n",
    "                TN, FP, FN, TP = sklearn.metrics.confusion_matrix(results[\"true\"], results[\"pred\"]).ravel()\n",
    "                score = FP / (TP + FP)\n",
    "            except:\n",
    "                score = 1\n",
    "        elif metric == 'pod':\n",
    "            try:\n",
    "                TN, FP, FN, TP = sklearn.metrics.confusion_matrix(results[\"true\"], results[\"pred\"]).ravel()\n",
    "                score = TP / (TP + FN)\n",
    "            except: \n",
    "                score = 1\n",
    "        result[metric] = score\n",
    "        #print(metric, round(score, 3))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transforms(transforms, image):\n",
    "    im = {\"image\": image}\n",
    "    for image_transform in transforms:\n",
    "        im = image_transform(im)\n",
    "    image = im[\"image\"]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"ML-for-Derecho\")\n",
    "\n",
    "import torch_funcs\n",
    "import torch_s2s_dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import xskillscore as xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_negone(ds, minv, maxv):\n",
    "    return (((ds + 1) / 2) * (maxv - minv)) + minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "available_ncpus = len(psutil.Process().cpu_affinity())\n",
    "\n",
    "# Set up the GPU\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\") if not is_cuda else torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda 8\n"
     ]
    }
   ],
   "source": [
    "print(device, available_ncpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"gan.yml\" #\"../config/gan.yml\"\n",
    "with open(config) as cf:\n",
    "    conf = yaml.load(cf, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "seed = 1000 if \"seed\" not in conf else conf[\"seed\"]\n",
    "seed_everything(seed)\n",
    "\n",
    "save_loc = conf[\"save_loc\"]\n",
    "os.makedirs(save_loc, exist_ok = True)\n",
    "os.makedirs(os.path.join(save_loc, \"images\"), exist_ok = True)\n",
    "if not os.path.isfile(os.path.join(save_loc, \"model.yml\")):\n",
    "    shutil.copyfile(config, os.path.join(save_loc, \"model.yml\"))\n",
    "\n",
    "# Trainer params\n",
    "train_batch_size = conf[\"trainer\"][\"train_batch_size\"]\n",
    "valid_batch_size = conf[\"trainer\"][\"valid_batch_size\"]\n",
    "\n",
    "epochs = conf[\"trainer\"][\"epochs\"]\n",
    "batches_per_epoch = conf[\"trainer\"][\"batches_per_epoch\"]\n",
    "Tensor = torch.cuda.FloatTensor if is_cuda else torch.FloatTensor\n",
    "adv_loss = conf[\"trainer\"][\"adv_loss\"]\n",
    "lambda_gp = conf[\"trainer\"][\"lambda_gp\"]\n",
    "mask_penalty = conf[\"trainer\"][\"mask_penalty\"]\n",
    "regression_penalty = conf[\"trainer\"][\"regression_penalty\"]\n",
    "train_gen_every = conf[\"trainer\"][\"train_gen_every\"]\n",
    "train_disc_every = conf[\"trainer\"][\"train_disc_every\"]\n",
    "threshold = conf[\"trainer\"][\"threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessing transforms\n",
    "if \"Normalize\" in conf[\"transforms\"][\"training\"]:\n",
    "    conf[\"transforms\"][\"validation\"][\"Normalize\"][\"mode\"] = conf[\"transforms\"][\"training\"][\"Normalize\"][\"mode\"]\n",
    "    conf[\"transforms\"][\"inference\"][\"Normalize\"][\"mode\"] = conf[\"transforms\"][\"training\"][\"Normalize\"][\"mode\"]\n",
    "\n",
    "train_transforms = LoadTransformations(conf[\"transforms\"][\"training\"])\n",
    "valid_transforms = LoadTransformations(conf[\"transforms\"][\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'tas2m'\n",
    "wks = 2\n",
    "\n",
    "train = torch_s2s_dataset.S2SDataset(\n",
    "    \n",
    "    week=wks, variable=var, norm='minmax', region='fixed',\n",
    "    \n",
    "    minv=None, maxv=None, mnv=None, stdv=None,\n",
    "    \n",
    "    lon0=250., lat0=30., dxdy=32., feat_topo=True, feat_lats=True, feat_lons=True,\n",
    "    \n",
    "    startdt='1999-02-01', enddt='2015-12-31', homedir='/glade/scratch/molina/'\n",
    ")\n",
    "\n",
    "valid = torch_s2s_dataset.S2SDataset(\n",
    "    \n",
    "    week=wks, variable=var, norm='minmax', region='fixed',\n",
    "    \n",
    "    minv=train.min_val, maxv=train.max_val, mnv=None, stdv=None,\n",
    "    \n",
    "    lon0=250., lat0=30., dxdy=32., feat_topo=True, feat_lats=True, feat_lons=True,\n",
    "    \n",
    "    startdt='2016-01-01', enddt='2017-12-31', homedir='/glade/scratch/molina/'\n",
    ")\n",
    "\n",
    "tests = torch_s2s_dataset.S2SDataset(\n",
    "    \n",
    "    week=wks, variable=var, norm='minmax', region='fixed',\n",
    "    \n",
    "    minv=train.min_val, maxv=train.max_val, mnv=None, stdv=None,\n",
    "    \n",
    "    lon0=250., lat0=30., dxdy=32., feat_topo=True, feat_lats=True, feat_lons=True,\n",
    "    \n",
    "    startdt='2018-01-01', enddt='2020-12-31', homedir='/glade/scratch/molina/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train,\n",
    "#     batch_size=train_batch_size,\n",
    "#     num_workers=available_ncpus//2,\n",
    "#     pin_memory=True,\n",
    "#     shuffle=True)\n",
    "\n",
    "# valid_loader = torch.utils.data.DataLoader(\n",
    "#     valid,\n",
    "#     batch_size=train_batch_size,\n",
    "#     num_workers=available_ncpus//2,\n",
    "#     pin_memory=True,\n",
    "#     shuffle=False)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=train_batch_size, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid, batch_size=train_batch_size, shuffle=False, drop_last=False)\n",
    "tests_loader = DataLoader(tests, batch_size=train_batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = load_model(conf[\"generator\"]).to(device) \n",
    "discriminator = load_model(conf[\"discriminator\"]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = smp.Unet(\n",
    "#     encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "#     encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "#     in_channels=4,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "#     classes=1,                      # model output channels (number of classes in your dataset)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /glade/work/schreck/py37/lib/python3.7/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "adv_loss = conf[\"trainer\"][\"adv_loss\"]\n",
    "if adv_loss == \"bce\":\n",
    "    adversarial_loss = torch.nn.BCELoss().to(device)\n",
    "    \n",
    "perceptual_alex = lpips.LPIPS(net='alex').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, generator.parameters()),\n",
    "    lr = conf[\"optimizer_G\"][\"learning_rate\"],\n",
    "    betas = (conf[\"optimizer_G\"][\"b0\"], conf[\"optimizer_G\"][\"b1\"]))\n",
    "\n",
    "optimizer_D = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, discriminator.parameters()), \n",
    "    lr = conf[\"optimizer_D\"][\"learning_rate\"], \n",
    "    betas = (conf[\"optimizer_D\"][\"b0\"], conf[\"optimizer_D\"][\"b1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(discriminator, real_imgs, gen_imgs):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    alpha = torch.rand(real_imgs.size(0), 1, 1, 1).cuda().expand_as(real_imgs)\n",
    "    interpolated = Variable(alpha * real_imgs.data + (1 - alpha) * gen_imgs.data, requires_grad=True)\n",
    "    out = discriminator(interpolated)[1]\n",
    "    grad = torch.autograd.grad(outputs=out,\n",
    "                               inputs=interpolated,\n",
    "                               grad_outputs=torch.ones(out.size()).cuda(),\n",
    "                               retain_graph=True,\n",
    "                               create_graph=True,\n",
    "                               only_inputs=True)[0]\n",
    "    grad = grad.view(grad.size(0), -1)\n",
    "    grad_l2norm = torch.sqrt(torch.sum(grad ** 2, dim=1))\n",
    "    d_loss_gp = torch.mean((grad_l2norm - 1) ** 2)\n",
    "    return d_loss_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_G_decay = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=30, gamma=0.2)\n",
    "lr_D_decay = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=30, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 D_loss -0.044851 D_reg 241.917496 G_loss -0.279516 G_reg    nan p_real 0.5877 real_acc 0.2344 fake_acc 0.8750:  13%|█▎        | 13/100 [00:29<03:20,  2.30s/it]\n",
      "Epoch 1 D_loss 0.010148 D_reg 534.407715 G_loss -0.275837 G_reg    nan p_real 0.5952 real_acc 0.2344 fake_acc 0.7344:  13%|█▎        | 13/100 [00:26<02:55,  2.02s/it]\n",
      "Epoch 2 D_loss 0.038002 D_reg 277.065369 G_loss -0.284760 G_reg    nan p_real 0.5966 real_acc 0.1562 fake_acc 0.7500:  13%|█▎        | 13/100 [00:25<02:52,  1.98s/it]\n",
      "Epoch 3 D_loss -0.029194 D_reg 110.951462 G_loss -0.293972 G_reg    nan p_real 0.5921 real_acc 0.3438 fake_acc 0.7656:  13%|█▎        | 13/100 [00:26<02:55,  2.02s/it]\n",
      "Epoch 4 D_loss 0.030986 D_reg 295.695953 G_loss -0.293794 G_reg    nan p_real 0.5877 real_acc 0.2031 fake_acc 0.7031:  13%|█▎        | 13/100 [00:26<02:57,  2.04s/it]\n",
      "Epoch 5 D_loss -0.031382 D_reg 146.958588 G_loss -0.265491 G_reg    nan p_real 0.5840 real_acc 0.2500 fake_acc 0.7656:  13%|█▎        | 13/100 [00:26<02:58,  2.05s/it]\n",
      "Epoch 6 D_loss 0.041104 D_reg 138.974731 G_loss -0.279644 G_reg    nan p_real 0.5770 real_acc 0.1719 fake_acc 0.7344:  13%|█▎        | 13/100 [00:26<02:58,  2.05s/it]\n",
      "Epoch 7 D_loss -0.003892 D_reg 267.223419 G_loss -0.264939 G_reg    nan p_real 0.5743 real_acc 0.2500 fake_acc 0.7656:  13%|█▎        | 13/100 [00:26<02:57,  2.04s/it]\n",
      "Epoch 8 D_loss -0.017457 D_reg 112.740128 G_loss -0.253389 G_reg    nan p_real 0.5697 real_acc 0.2344 fake_acc 0.7969:  13%|█▎        | 13/100 [00:26<03:00,  2.07s/it]\n",
      "Epoch 9 D_loss -0.024705 D_reg 228.429047 G_loss -0.260872 G_reg    nan p_real 0.5770 real_acc 0.2344 fake_acc 0.7969:  13%|█▎        | 13/100 [00:26<02:58,  2.05s/it]\n",
      "Epoch 10 D_loss 0.027469 D_reg 232.027069 G_loss -0.256291 G_reg    nan p_real 0.5733 real_acc 0.1719 fake_acc 0.7344:  13%|█▎        | 13/100 [00:26<02:57,  2.04s/it]\n",
      "Epoch 11 D_loss -0.005703 D_reg 42.585899 G_loss -0.255801 G_reg    nan p_real 0.5752 real_acc 0.2656 fake_acc 0.7500:  13%|█▎        | 13/100 [00:26<02:59,  2.06s/it]\n",
      "Epoch 12 D_loss nan D_reg nan G_loss -0.260291 G_reg    nan p_real 0.5838 real_acc nan fake_acc nan:   6%|▌         | 6/100 [00:12<03:13,  2.06s/it]"
     ]
    }
   ],
   "source": [
    "results = defaultdict(list)\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    ### Train\n",
    "    dual_iter = tqdm.tqdm(\n",
    "        enumerate(train_loader),\n",
    "        total = batches_per_epoch, \n",
    "        leave = True)\n",
    "    \n",
    "    train_results = defaultdict(list)\n",
    "    for i, x in dual_iter:\n",
    "        \n",
    "        img = x[\"input\"].squeeze(2)[:, :, :32, :32]\n",
    "        label = x[\"label\"].squeeze(2)[:, :, :32, :32]\n",
    "                            \n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(img.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(img.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(img.type(Tensor))\n",
    "                \n",
    "        # Sample noise as generator input\n",
    "        #z = Variable(Tensor(np.random.normal(0, 1.0, (holo_img.shape[0], 512))))\n",
    "        b, c, l, w = img.shape\n",
    "        z = Tensor(np.random.normal(0, 1.0, (b, 1, l, w)))\n",
    "        # C-GAN-like input using the synthethic image as conditional input\n",
    "        #gen_input = torch.cat([synthethic_imgs, z], 1)\n",
    "        # Generate a batch of images\n",
    "        \n",
    "        gen_imgs = generator(z)\n",
    "        \n",
    "        # Discriminate the fake images\n",
    "        _, verdict = discriminator(gen_imgs)\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "            \n",
    "        if (i + 1) % train_gen_every == 0:\n",
    "            \n",
    "            optimizer_G.zero_grad()\n",
    "            requires_grad(generator, True)\n",
    "            requires_grad(discriminator, False)\n",
    "            \n",
    "            # measure the generator's ability to fool the discriminator\n",
    "            if adv_loss == 'wgan-gp':\n",
    "                g_loss = -verdict.mean()\n",
    "            elif adv_loss == 'hinge':\n",
    "                g_loss = -verdict.mean()\n",
    "            elif adv_loss == 'bce':\n",
    "                g_loss = adversarial_loss(verdict, valid)\n",
    "            \n",
    "            # compute mask loss reg term\n",
    "            train_results[\"g_loss\"].append(g_loss.item())\n",
    "                \n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            # compute perception scores\n",
    "            p_score_real = perceptual_alex(gen_imgs[:, :3, :, :], real_imgs[:, :3, :, :]).mean()\n",
    "            train_results[\"p_real\"].append(p_score_real.item())\n",
    "            \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        \n",
    "        if (i + 1) % train_disc_every == 0:\n",
    "        \n",
    "            optimizer_D.zero_grad()\n",
    "            requires_grad(generator, False)\n",
    "            requires_grad(discriminator, True)\n",
    "\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "            _, disc_real = discriminator(real_imgs)\n",
    "            _, disc_synth = discriminator(gen_imgs.detach())\n",
    "            \n",
    "            train_results[\"real_acc\"].append(((disc_real > threshold) == valid).float().mean().item())\n",
    "            train_results[\"fake_acc\"].append(((disc_synth > threshold) == fake).float().mean().item())\n",
    "            \n",
    "            if adv_loss == 'wgan-gp':\n",
    "                real_loss = -torch.mean(disc_real) \n",
    "                fake_loss = disc_synth.mean() \n",
    "            elif adv_loss == 'hinge':\n",
    "                real_loss = torch.nn.ReLU()(1.0 - disc_real).mean() \n",
    "                fake_loss = torch.nn.ReLU()(1.0 + disc_synth).mean()             \n",
    "            elif adv_loss == 'bce':\n",
    "                real_loss = adversarial_loss(disc_real, valid) \n",
    "                fake_loss = adversarial_loss(disc_synth, fake) \n",
    "                \n",
    "            d_loss = real_loss + fake_loss \n",
    "            train_results[\"d_loss\"].append(d_loss.item())\n",
    "            \n",
    "            if adv_loss == 'wgan-gp':\n",
    "                # Compute gradient penalty\n",
    "                alpha = torch.rand(real_imgs.size(0), 1, 1, 1).cuda().expand_as(real_imgs)\n",
    "                interpolated = Variable(alpha * real_imgs.data + (1 - alpha) * gen_imgs.data, requires_grad=True)\n",
    "                out = discriminator(interpolated)[1]\n",
    "\n",
    "                grad = torch.autograd.grad(outputs=out,\n",
    "                                           inputs=interpolated,\n",
    "                                           grad_outputs=torch.ones(out.size()).cuda(),\n",
    "                                           retain_graph=True,\n",
    "                                           create_graph=True,\n",
    "                                           only_inputs=True)[0]\n",
    "\n",
    "                grad = grad.view(grad.size(0), -1)\n",
    "                grad_l2norm = torch.sqrt(torch.sum(grad ** 2, dim=1))\n",
    "                d_loss_gp = torch.mean((grad_l2norm - 1) ** 2)\n",
    "                d_loss_reg = lambda_gp * d_loss_gp\n",
    "                d_loss += d_loss_reg\n",
    "                train_results[\"d_reg\"].append(d_loss_reg.item())\n",
    "            \n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "        print_str =  f'Epoch {epoch}'\n",
    "        print_str += f' D_loss {np.mean(train_results[\"d_loss\"]):.6f}'\n",
    "        if adv_loss == 'wgan-gp':\n",
    "            print_str += f' D_reg {np.mean(train_results[\"d_reg\"]):.6f}'\n",
    "        print_str += f' G_loss {np.mean(train_results[\"g_loss\"]):6f}'\n",
    "        print_str += f' G_reg {np.mean(train_results[\"g_reg\"]):6f}'\n",
    "        print_str += f' p_real {np.mean(train_results[\"p_real\"]):.4f}'\n",
    "        print_str += f' real_acc {np.mean(train_results[\"real_acc\"]):.4f}'\n",
    "        print_str += f' fake_acc {np.mean(train_results[\"fake_acc\"]):.4f}'\n",
    "        dual_iter.set_description(print_str)\n",
    "        dual_iter.refresh()\n",
    "        \n",
    "        if i == batches_per_epoch and i > 0:\n",
    "            break\n",
    "        \n",
    "    # Save the dataframe to disk\n",
    "    results[\"epoch\"].append(epoch)\n",
    "    results[\"d_loss\"].append(np.mean(train_results[\"d_loss\"]))\n",
    "    if adv_loss == 'wgan-gp':\n",
    "        results[\"d_loss_reg\"].append(np.mean(train_results[\"d_reg\"]))\n",
    "    results[\"g_loss\"].append(np.mean(train_results[\"g_loss\"]))\n",
    "    results[\"g_reg\"].append(np.mean(train_results[\"g_reg\"]))\n",
    "    results[\"perception\"].append(np.mean(train_results[\"p_real\"]))\n",
    "    results[\"real_acc\"].append(np.mean(train_results[\"real_acc\"]))\n",
    "    results[\"fake_acc\"].append(np.mean(train_results[\"syn_acc\"]))\n",
    "\n",
    "    metric = \"custom\"\n",
    "    metric_value = results[\"perception\"][-1]\n",
    "    results[metric].append(metric_value)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(results).reset_index()\n",
    "    df.to_csv(f'{conf[\"save_loc\"]}/training_log.csv', index=False)\n",
    "    \n",
    "    save_image(real_imgs.data[:9], f'{conf[\"save_loc\"]}/images/real_{epoch}.png', nrow=3, normalize=True)\n",
    "    save_image(gen_imgs.data[:9], f'{conf[\"save_loc\"]}/images/pred_{epoch}.png', nrow=3, normalize=True)\n",
    "\n",
    "    # Save the model\n",
    "    state_dict = {\n",
    "        'epoch': epoch,\n",
    "        'discriminator_state_dict': discriminator.state_dict(),\n",
    "        'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "        'generator_state_dict': generator.state_dict(),\n",
    "        'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "    }\n",
    "    torch.save(state_dict, f'{conf[\"save_loc\"]}/best.pt')\n",
    "    \n",
    "    # Anneal learning rates \n",
    "    lr_G_decay.step(epoch)\n",
    "    lr_D_decay.step(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
